{"run":{"run_id":"8d7eeead4930a701d46f0ee6f5e8ff4249328bc7d32a32ab4c6623e70058489e","created":1689153273655,"run_type":"deploy","config":{"blocks":{"MODEL":{"provider_id":"openai","model_id":"gpt-3.5-turbo","function_call":null,"use_cache":true},"DATASOURCE":{"data_sources":[{"workspace_id":"b74db6909a","data_source_id":"kayobe"}],"top_k":12,"filter":{"tags":null,"timestamp":null},"use_cache":false}}},"status":{"run":"succeeded","blocks":[{"block_type":"input","name":"INPUT","status":"succeeded","success_count":1,"error_count":0},{"block_type":"data_source","name":"DATASOURCE","status":"succeeded","success_count":1,"error_count":0},{"block_type":"chat","name":"MODEL","status":"succeeded","success_count":1,"error_count":0},{"block_type":"code","name":"FINAL","status":"succeeded","success_count":1,"error_count":0}]},"traces":[[["input","INPUT"],[[{"value":{"question":"Explain how to setup a machine for OpenStack."},"error":null,"meta":null}]]],[["data_source","DATASOURCE"],[[{"value":[{"data_source_id":"kayobe","created":1689073303707,"document_id":"page1","timestamp":1689073303707,"tags":[],"source_url":null,"hash":"1057285e37e9ea35071816dd825995809e73ea03b45e04f31ef2d83e2a62c168","text_size":88780,"chunk_count":78,"chunks":[{"text":", you should have three storage nodes in your OpenStack deployment. You should be able to attach volumes to virtual machines and launch an instance from a volume. Task 2-1: Ceph integration Defining the storage machines Edit tenks.yml in the training directory to add another node type named storage. You can follow a very similar format to the existing types, however it requires two volumes, as one will be for Ceph. The first volume should be 15GB and the other should be 20GB (The second volume must be larger, otherwise Ceph and the OS will clash). Once the format is created, add three machines of this type to the specs dict. Kayobe configuration Optionally, add the storage nodes to network-allocation.yml in the training directory and pick three new IPs for the nodes. This will be done automatically if you do not make any changes. Edit overcloud.yml to add the new nodes to the storage group. Copy the storage.yml file from src/kayobe-config/etc/kayobe/ to the training directory, and set storage_lvm_groups: [] Enable Cinder in kolla.yml There are three variables to be set in kolla/globals.yml , which enable Ceph as the backend for Nova, Glance, and Cinder.","hash":"4ed253dbad922bf59feea862e8532b52ffaffda69034c81755e0675818a4e137","offset":18,"vector":null,"score":0.860828697681427},{"text":" outages and failures. If the networking is broken, you will probably need to reboot your machine before you can access it again. Tenks doesn’t really like it when that happens so look here for a guide on how to restart the stopped services. Kayobe Deployment Project - StackHPC https://wiki.stackhpc.com/doc/kayobe-deployment-project... 1 of 42 11/07/2023, 12:01 The objective of this exercise is to set up a basic AUFN style OpenStack environment. The instructions should detail all the steps required to complete the task. By the end of the task, you should: To complete the exercise, you should have a functioning OpenStack deployment that can host virtual machines. You should be able to interact with the deployment using the horizon interface. The deployment should be easily rebuilt using your own fork of stackhpc-kayobe-config and a customised version of the provided deployment script. Task 1-1: Machine setup Boot a CentOS Stream 8 baremetal-32 machine on SMS lab Download and extract the training environment Rename the directory for consistency Run the configure-machine.sh script Don’t worry if you see a No such file or directory warning here. It can be safely ignored. From this","hash":"660944a7166712caa7ca3e1e17124be613c23f5f367e65da7e3af90c4d3447b3","offset":1,"vector":null,"score":0.8509093523025513},{"text":"obe-config contains a few different environments designed for CI. One of the earlier tasks was to download the training environment and add it to this directory. It is here that you will need to make changes. Have a look at the environments now: Then cd to the training environment This is where you will need to make configuration changes to your environment throughout this project. Open the network-allocation.yml file: It will show the IPs of all the machines on the network. The seed hypervisor is the machine you are on at the moment. The seed is a regular VM, while the compute and controller nodes are virtual baremetal machines provided by tenks. All of the nodes in the list are accessible via SSH with the stack user e.g. libvirt On your control host, run ls src/kayobe-config/etc/kayobe/environments 1 cd src/kayobe-config/etc/kayobe/environments/training 1 cat network-allocation.yml 1 ssh stack@192.168.33.x 1 Kayobe Deployment Project - StackHPC https://wiki.stackhpc.com/doc/kayobe-deployment-project... 6 of 42 11/07/2023, 12:01 You should see six virtual machines. The seed, plus two compute","hash":"8da1e34285e6998dcc6b527cc3b2ecd0fd7221087a7b90f35cb26c7210442cdf","offset":10,"vector":null,"score":0.8476057052612305},{"text":" your web browser in order to use the connection. In this case, it is often easiest to use a different web browser to the one you normally use e.g. Firefox instead of Chrome. Once you have a connection, you should see an OpenStack login page. You can find the credentials in src/kayobe-config/etc/kolla/public-openrc.sh as OS_USERNAME and OS_PASSWORD . When you are inside, try creating your own VM using the GUI. Use the CirrOS image, an m1.tiny flavour, mykey , and the demo-net network. Select it and navigate across to the console tab and try executing some commands. To make it accessible from the outside world, create a floating IP on public1 and attach it. Then see if you can connect to it via SSH in the same way as the first VM. Task 1-4: Exploring the environment openstack server show test-vm-1 1 ssh cirros@<the ip from test-vm-1> 1 Kayobe Deployment Project - StackHPC https://wiki.stackhpc.com/doc/kayobe-deployment-project... 5 of 42 11/07/2023, 12:01 The Kayobe environment The configuration files for Kayobe","hash":"463356dc0dfd739a86b753c7f2c8fd0d895d9f8de6eb2a80901ae45d0d8d94cd","offset":8,"vector":null,"score":0.8365112543106079},{"text":" point onwards, you will regularly need to run long and complex scripts. There is always the possibility of failures occurring. It is strongly recommended that you take precautions to minimise failures and reduce time spent waiting for things to run. Using tmux or sending your running process to the background will allow you to run commands while not maintaining an active SSH connection. Even if you don’t plan on closing anything manually, network outages or your computer going to sleep at lunch can lose hours of work. It can also be beneficial to log your terminal output to a file. In the event that a failure occurs early on and the history is overwritten, or your terminal crashes, having a clear log can be very useful. Task 1-2: OpenStack Setup • Feel comfortable with the basic file structure • Given a baseline kayobe-config, be able to build a simple environment wget https://github.com/stackhpc/kayobe-training-environment/tarball/master -O - | tar -xz 1 mv stackhpc-kayobe-training-environment* training 1 ./training/configure-machine.sh 1 � . In the home directory, create two directories named src and venvs. � . Create a fork ( not branch) of stackhpc-kayobe-config","hash":"cd2a8fbbae92a6cb1e934d94c724a1b38463db9bb3cf616b324e8bb892e83b47","offset":2,"vector":null,"score":0.8308550715446472},{"text":" look in the OpenStack folder. If you do not see the list of dashboards, you will need to go back and update your configuration. The default Grafana dashboards in stackhpc-kayobe-config need to be added to the training environment and the service needs to be reconfigured. It is well worth looking through all the dashboards in this folder. Take a few minutes now just to see what is in each one. Some may just be broken, as long as some of them are working then it’s not a problem. for run in {1..10}; do openstack server create --image cirros --flavor m1.tiny --key-name mykey --network demo-net --os-compute-api-version 2.74 --hypervisor-hostname compute1 test$run; done 1 Tangent on overcommitment It is worth noting here that while the compute machines only have 4 cores, overcommitting allows them to support many more virtual machines. vCPUs don’t have to map 1:1 with real cores. As long as the ratio isn’t too high, the performance loss is usually minimal. A lot of the time, VMs can sit idle with very low utilisation. Overcommitment can be managed","hash":"039217690c5a6a4e45ab90ae322e17d6df3a7dd492d7bd8e84cdde0a06ef12d4","offset":38,"vector":null,"score":0.8260266184806824},{"text":"ay.io/ceph/ceph:v16.2.5\" � . Set the cephadm_pools cephadm_osd_spec and cephadm_keys yourself. openstack volume create --size 5 test-volume 1 openstack server add volume test-vm-1 test-volume 1 Kayobe Deployment Project - StackHPC https://wiki.stackhpc.com/doc/kayobe-deployment-project... 12 of 42 11/07/2023, 12:01 c ) SSH into one of your storage nodes e.g. Take a look at the containers running there You should see four ceph containers They will share a generated name, however the important part is the suffix. On the storage nodes, you can run Ceph commands if you prefix them with sudo cephadm shell -- For example, to get an overview of the state, run To make it easier to run multiple Ceph commands, use: This command starts a Ceph shell which saves having to prefix every command with sudo cephadm shell -- . Ceph storage is divided up into different pools. To list them, run: You should see four pools: Here we can see how Ceph serves as a backed storage solution for Glance, Cinder, and Nova.","hash":"04a7591f27e1ffead334834b8085eb11813db701e0c48081273f5833e7dfe221","offset":21,"vector":null,"score":0.8258820176124573},{"text":"tu There are two bugs you need to work around: � . You will need to edit requirements.yml and pin the version of the openstack.cloud collection to version 1.10.0 . See here for more information on the requirements files. � . The exact instructions in the readme in the example repository will not work on Centos 8 Stream. You must use python3 -m venv venv-name rather than virtualenv venv-name to create the virtual environment you use to run the tool. You also need to make sure you do not make the virtual environment from within another virtual environment. This bit can be unnecessarily fiddly to fix so don’t hesitate to ask for help from either me (Alex) or Scott. Kayobe Deployment Project - StackHPC https://wiki.stackhpc.com/doc/kayobe-deployment-project... 28 of 42 11/07/2023, 12:01 system. It is probably worth writing your config, then redeploy everything from scratch using the deploy.sh script. You may get a timeout during kayobe overcloud host configure that looks like this: If so, check the interface configuration under /etc/sysconfig/network-scripts /ifcfg-eth1 on the overcloud hosts. BOOTPROTO should","hash":"20ef26068b773b55a95a41502021165c607ce2d10b406e7eeefad706520b9f10","offset":52,"vector":null,"score":0.8226596713066101},{"text":" in the VM pane should also create activity as they are being sent over SSH. You experiment with different traffic, here are a few examples: openstack server create --key-name mykey --flavor m1.tiny --image cirros --network demo-net test-vm-2 1 ssh cirros@<floating-ip> 1 ssh stack@192.168.33.(6 or 7) 1 docker exec nova_libvirt virsh domiflist instance-00000003 (or something like that) 1 sudo tcpdump -v -n -e -i tap710bba5a-95 1 ssh cirros@<ip> 1 Kayobe Deployment Project - StackHPC https://wiki.stackhpc.com/doc/kayobe-deployment-project... 10 of 42 11/07/2023, 12:01 Exercise 2: Cephadm Exercise outline The objective of this task is to integrate a Ceph storage cluster into your OpenStack deployment. For this exercise, some of the steps have been purposefully omitted. You will need to use the stackhpc guide for configuring Cephadm in Kayobe, available here . By the end of the task, you should: To complete the exercise","hash":"985bfbb3d8fe85a230bec4f596162dade9d31fecca866971c27e18d22943081d","offset":17,"vector":null,"score":0.8226362466812134},{"text":"all 1 sudo virsh dumpxml seed | less 1 diff <(sudo virsh dumpxml compute0) <(sudo virsh dumpxml controller0) 1 ssh stack@192.168.33.5 1 docker ps 1 docker exec -it bifrost_deploy bash 1 baremetal --help 1 baremetal node list --os-cloud bifrost 1 Kayobe Deployment Project - StackHPC https://wiki.stackhpc.com/doc/kayobe-deployment-project... 7 of 42 11/07/2023, 12:01 You should see your five overcloud machines here. Inspect one of your choice by running Some actions, such as tearing down and redeploying the overcloud, are not possible when the provisioning state of a node is not active. You would therefore have to manually set maintenance mode: You don’t need to do this now. Navigate back to the seed hypervisor by pressing Ctrl+d twice. Pulp The local pulp container normally serves as a midway point between Ark and the OpenStack deployment. A blog post of how this works is available here . If you haven’t seen them already, you can find the client documentation here and the internal documentation here . You probably should read all three","hash":"025f6500ae8c66e5d8318cfd41c27b92dace8edb727012d0b2b1100fcb92dcb8","offset":12,"vector":null,"score":0.8197092413902283},{"text":".stackhpc.com/doc/kayobe-deployment-project... 38 of 42 11/07/2023, 12:01 To complete the exercise, you should configure and deploy tempest to test your OpenStack system. Task 5-1: Tempest testing Tempest is a testing suite used for integration testing on openstack deployments. For this task, you should run through the default test suite of about 300 tests. You should use Kayobe automation, documentation for which is available here. For now, use the default configuration, without any overrides. You shouldn’t need to make any extra openstack resources. There are two errors you may come across. The first is a python error. The virtual environment that is used by default does not contain the docker package. The solution is to install it manually. The error text contains the path of the python executable. In the same directory is the pip executable. Use it to install the docker package. The second is a docker error. The pulp docker registry does not use https , which is a fatal error by default. Information on how to work around this error can be found here . Remember to restart docker after making your changes. The tests should all pass or be skipped, but it’s not a major","hash":"482274765da48a8000da5e777ca611320c433f47b88b12ceb98d16e941d3f776","offset":70,"vector":null,"score":0.8196895122528076},{"text":" #TODO: add command to do this here, don’t forget to specify the disk-format Testing With everything configured properly, you should now be able to create volumes in your OpenStack environment with: And attach it to your test VM with Also, try booting a VM from a volume through the horizon interface. Horizon abstracts some of the complexity away, so if you select an image as the source and create a new root volume, it will use the image to automatically create a bootable volume. Navigate to the instances page and create a new instance. When selecting the source choose image , enable create new volume , and choose a volume size of 6gb. Also, enable Delete Volume on Instance Delete . This can be a very useful setting because, as you may have guessed, the volume will otherwise persist even if the instance is deleted. This can quickly use up a lot of storage when people inevitably forget to delete their old volumes. Task 2-2: Exploring the environment Cephadm and OpenStack Later on, a second tmux window will be needed, so create one now (press ctrl+b then � . Set cephadm_ec_profiles: [] � . Set cephadm_crush_rules: [] � . Set cephadm_image: \"qu","hash":"6a3db8c3b6659eb2a6e798709da8ae9d376faf676eb68b3f06de81a6a3cf80bc","offset":20,"vector":null,"score":0.8175051808357239}],"token_count":3072}],"error":null,"meta":null}]]],[["chat","MODEL"],[[{"value":{"message":{"role":"assistant","content":"To set up a machine for OpenStack, follow these steps:\n\n1. Boot a CentOS Stream 8 baremetal machine on the SMS lab.\n2. Download and extract the training environment.\n3. Rename the directory for consistency.\n4. Run the `configure-machine.sh` script.\n5. Make changes to the `network-allocation.yml` file to configure the IP addresses of the machines.\n6. Edit the `tenks.yml` file to define the storage machines and their volumes.\n7. Add the storage nodes to the `overcloud.yml` file.\n8. Enable Cinder as the backend for Nova, Glance, and Cinder in the `kolla.yml` file.\n9. Integrate a Ceph storage cluster into your OpenStack deployment using the steps provided in the StackHPC guide for configuring Cephadm in Kayobe.\n10. Configure and deploy tempest to test your OpenStack system using the Kayobe automation and documentation.\n11. Test the volume creation and attachment by creating volumes and attaching them to test VMs.\n12. Explore the environment and familiarize yourself with the Cephadm and OpenStack components.\n\nBy following these steps, you will have a machine set up for OpenStack with integrated Ceph storage and the ability to test your deployment using tempest."}},"error":null,"meta":{"logs":[]}}]]],[["code","FINAL"],[[{"value":"To set up a machine for OpenStack, follow these steps:\n\n1. Boot a CentOS Stream 8 baremetal machine on the SMS lab.\n2. Download and extract the training environment.\n3. Rename the directory for consistency.\n4. Run the `configure-machine.sh` script.\n5. Make changes to the `network-allocation.yml` file to configure the IP addresses of the machines.\n6. Edit the `tenks.yml` file to define the storage machines and their volumes.\n7. Add the storage nodes to the `overcloud.yml` file.\n8. Enable Cinder as the backend for Nova, Glance, and Cinder in the `kolla.yml` file.\n9. Integrate a Ceph storage cluster into your OpenStack deployment using the steps provided in the StackHPC guide for configuring Cephadm in Kayobe.\n10. Configure and deploy tempest to test your OpenStack system using the Kayobe automation and documentation.\n11. Test the volume creation and attachment by creating volumes and attaching them to test VMs.\n12. Explore the environment and familiarize yourself with the Cephadm and OpenStack components.\n\nBy following these steps, you will have a machine set up for OpenStack with integrated Ceph storage and the ability to test your deployment using tempest.","error":null,"meta":{"logs":[]}}]]]],"specification_hash":"fd89f27d5b93e02466d61e0b224b876e20f2e2ed258447ba676725e31c65152d","results":[[{"value":"To set up a machine for OpenStack, follow these steps:\n\n1. Boot a CentOS Stream 8 baremetal machine on the SMS lab.\n2. Download and extract the training environment.\n3. Rename the directory for consistency.\n4. Run the `configure-machine.sh` script.\n5. Make changes to the `network-allocation.yml` file to configure the IP addresses of the machines.\n6. Edit the `tenks.yml` file to define the storage machines and their volumes.\n7. Add the storage nodes to the `overcloud.yml` file.\n8. Enable Cinder as the backend for Nova, Glance, and Cinder in the `kolla.yml` file.\n9. Integrate a Ceph storage cluster into your OpenStack deployment using the steps provided in the StackHPC guide for configuring Cephadm in Kayobe.\n10. Configure and deploy tempest to test your OpenStack system using the Kayobe automation and documentation.\n11. Test the volume creation and attachment by creating volumes and attaching them to test VMs.\n12. Explore the environment and familiarize yourself with the Cephadm and OpenStack components.\n\nBy following these steps, you will have a machine set up for OpenStack with integrated Ceph storage and the ability to test your deployment using tempest.","error":null,"meta":{"logs":[]}}]]}}